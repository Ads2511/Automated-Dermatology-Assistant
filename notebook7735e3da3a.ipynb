{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11038090,"sourceType":"datasetVersion","datasetId":6875259}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import efficientnet_b3\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Paths\ndata_dir = \"/kaggle/input/ham10000/HAM10000_images/\"\nmetadata_path = \"/kaggle/input/ham10000/HAM10000_metadata.csv\"\n\n# Hyperparameters\nBATCH_SIZE = 8  # Reduced to prevent OOM\nEPOCHS = 100\nLEARNING_RATE = 1e-4\nIMAGE_SIZE = (300, 300)\n\n# Data Transformations\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load Data\ndataset = datasets.ImageFolder(data_dir, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Model Setup\nmodel = efficientnet_b3(weights=\"IMAGENET1K_V1\")\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 7)  # 7 classes in HAM10000\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscaler = GradScaler()\n\n# TensorBoard Logger\nwriter = SummaryWriter(\"runs/EfficientNetB3_HAM10000\")\n\n# Training Function\ndef train_model():\n    best_val_loss = float(\"inf\")\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        correct, total = 0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            \n            with autocast():  # Mixed Precision Training\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n        train_loss = running_loss / len(train_loader)\n        train_acc = correct / total\n        \n        # Validation Phase\n        model.eval()\n        val_loss, val_correct, val_total = 0.0, 0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_correct += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n        \n        val_loss /= len(val_loader)\n        val_acc = val_correct / val_total\n        \n        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Validation\": val_loss}, epoch)\n        writer.add_scalars(\"Accuracy\", {\"Train\": train_acc, \"Validation\": val_acc}, epoch)\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(\"Best model saved!\")\n\n        torch.cuda.empty_cache()  # Free GPU memory\n\n# Run Training\ntrain_model()\n\n# Load Best Model for Testing\nmodel.load_state_dict(torch.load(\"best_model.pth\"))\nmodel.eval()\n\n# Testing Function\ndef test_model():\n    test_dataset = datasets.ImageFolder(data_dir, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    \n    test_acc = correct / total\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Run Testing\ntest_model()\n\nprint(\"Training and Testing Completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:22:22.125145Z","iopub.execute_input":"2025-03-15T13:22:22.125440Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n100%|██████████| 47.2M/47.2M [00:00<00:00, 228MB/s]\n<ipython-input-4-84aaa2c5c043>:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n<ipython-input-4-84aaa2c5c043>:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():  # Mixed Precision Training\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/100] - Train Loss: 0.0518, Train Acc: 0.9965, Val Loss: 0.0015, Val Acc: 1.0000\nBest model saved!\nEpoch [2/100] - Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\nBest model saved!\nEpoch [3/100] - Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\nBest model saved!\nEpoch [4/100] - Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\nBest model saved!\nEpoch [5/100] - Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\nBest model saved!\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}