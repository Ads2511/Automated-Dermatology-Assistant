{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm  # Progress Bar\n",
    "\n",
    "#  Set paths\n",
    "DATA_DIR = \"C:/Derma/Data/\"\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"HAM10000_metadata.csv\")\n",
    "IMAGE_PATH = os.path.join(DATA_DIR, \"HAM10000_images/\")\n",
    "CHECKPOINT_DIR = \"./checkpoints/\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpit\\AppData\\Local\\Temp\\ipykernel_4364\\1227445343.py:63: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1/20:   0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df['path'] = df['image_id'].apply(lambda x: os.path.join(IMAGE_PATH, x + \".jpg\"))\n",
    "label_map = {label: idx for idx, label in enumerate(df['dx'].unique())}\n",
    "df['label'] = df['dx'].map(label_map)\n",
    "\n",
    "#  Custom Dataset\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Train-Test Split\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_dataset = SkinDataset(train_df, transform=transform)\n",
    "val_dataset = SkinDataset(val_df, transform=transform)\n",
    "\n",
    "#  Auto-tune batch size based on GPU memory\n",
    "BATCH_SIZE = 16  # Adjust based on available VRAM\n",
    "try:\n",
    "    _ = torch.randn((BATCH_SIZE, 3, 224, 224), device=\"cuda\")\n",
    "except RuntimeError:\n",
    "    BATCH_SIZE = 8  # Reduce batch size if OOM occurs\n",
    "\n",
    "#  Use `pin_memory` for faster data transfer\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "#  Load Model (EfficientNet-B3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.efficientnet_b3(weights=\"IMAGENET1K_V1\")\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(label_map))\n",
    "model = model.to(device)\n",
    "\n",
    "#  Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "#  Mixed Precision for Faster Training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "accumulation_steps = 4  #  Accumulate gradients to reduce memory usage\n",
    "\n",
    "#  Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20, patience=5):\n",
    "    best_val_acc = 0\n",
    "    early_stop_counter = 0\n",
    "    log_file = \"training_log.csv\"\n",
    "    \n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,train_acc,val_acc,time_taken\\n\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        #  Show progress bar\n",
    "        train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "        \n",
    "        optimizer.zero_grad()  #  Reset gradients\n",
    "        for i, (images, labels) in enumerate(train_progress):\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():  #  Mixed precision\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()  #  Scaled gradient\n",
    "            if (i + 1) % accumulation_steps == 0:  #  Gradient Accumulation\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            #  Update progress bar\n",
    "            train_progress.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        #  Save log\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"{epoch+1},{running_loss/len(train_loader):.4f},{train_acc:.2f},{val_acc:.2f},{epoch_time:.2f}\\n\")\n",
    "\n",
    "        print(f\"\\nüìå Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f} - Train Acc: {train_acc:.2f}% - Val Acc: {val_acc:.2f}% - Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        #  Save Checkpoint every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\" Saved checkpoint at {checkpoint_path}\")\n",
    "\n",
    "        #  Save Best Model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_skin_model.pth\")\n",
    "            print(\"üéâ New Best Model Saved!\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"üö® Early Stopping Counter: {early_stop_counter}/{patience}\")\n",
    "\n",
    "        #  Early Stopping\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"‚èπÔ∏è Early Stopping Triggered! Training Stopped.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "#  Evaluation Function\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "#  Train Model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
